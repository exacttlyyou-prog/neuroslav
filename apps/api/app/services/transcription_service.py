import os
import whisper
import asyncio
import torch
from pathlib import Path
from loguru import logger
from typing import Optional, Union

class TranscriptionService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI Whisper.
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è Apple Silicon (Metal).
    """
    
    _instance = None
    _model = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(TranscriptionService, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        if torch.backends.mps.is_available():
            self.device = "mps" # Apple Silicon GPU
            logger.info("üöÄ Whisper –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Apple Silicon GPU (MPS)")
        elif torch.cuda.is_available():
            self.device = "cuda"
            logger.info("üöÄ Whisper –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å NVIDIA GPU (CUDA)")
        else:
            self.device = "cpu"
            logger.info("‚ÑπÔ∏è Whisper –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU")

    async def _get_model(self):
        """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏."""
        if self._model is None:
            logger.info("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper (small)...")
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop
            self._model = await asyncio.to_thread(whisper.load_model, "small", device=self.device)
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å Whisper –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return self._model

    async def transcribe(self, audio_path: Union[str, Path], language: str = "ru") -> Optional[str]:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ —Ç–µ–∫—Å—Ç.
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É (.wav, .mp3, etc)
            language: –Ø–∑—ã–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä—É—Å—Å–∫–∏–π)
            
        Returns:
            –¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        try:
            model = await self._get_model()
            audio_path = str(audio_path)
            
            if not os.path.exists(audio_path):
                logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
                return None

            logger.info(f"üéô –ù–∞—á–∞–ª–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Ñ–∞–π–ª–∞: {audio_path}...")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            # –û—Ç–∫–ª—é—á–∞–µ–º fp16 –¥–ª—è MPS, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏ (NaN)
            use_fp16 = (self.device == "cuda")
            
            result = await asyncio.to_thread(
                model.transcribe, 
                audio_path, 
                language=language,
                fp16=use_fp16
            )
            
            text = result.get("text", "").strip()
            logger.info(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ({len(text)} —Å–∏–º–≤.)")
            return text

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            return None

# Singleton instance
transcription_service = TranscriptionService()
