"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama (–ª–æ–∫–∞–ª—å–Ω—ã–π AI).
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–∞—Ç–∏–≤–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É ollama –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É —Å–µ—Ä–≤–µ—Ä—É.
"""
import json
from typing import TypeVar, Type, List, Dict, Any, Optional
from loguru import logger
from pydantic import BaseModel, ValidationError
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)

try:
    import ollama
except ImportError:
    raise ImportError("–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–∞–∫–µ—Ç ollama. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ollama")

from app.config import get_settings

T = TypeVar('T', bound=BaseModel)


class OllamaService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama."""
    
    def __init__(self, context_loader=None):
        settings = get_settings()
        self.context_loader = context_loader
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Ç–∏–≤–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É ollama
        self.client = ollama.Client(host=settings.ollama_base_url)
        
        self.model_name = settings.ollama_model
        self.max_tokens = settings.ollama_max_tokens
        self.temperature = settings.ollama_temperature
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((ValueError, ValidationError, json.JSONDecodeError)),
        reraise=True
    )
    async def analyze_meeting(
        self,
        content: str,
        context: List[str],
        response_schema: Type[T],
        sender_username: Optional[str] = None
    ) -> T:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –≤—Å—Ç—Ä–µ—á–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ RAG.
        
        Args:
            content: –¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤—Å—Ç—Ä–µ—á–∏
            context: –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ—à–ª—ã—Ö –≤—Å—Ç—Ä–µ—á (–∏–∑ RAG)
            response_schema: Pydantic –º–æ–¥–µ–ª—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
            sender_username: Username –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
            
        Returns:
            –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ T
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–æ—Ö–æ–∂–∏—Ö –≤—Å—Ç—Ä–µ—á
            context_text = ""
            if context:
                context_text = "\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ—à–ª—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö –≤—Å—Ç—Ä–µ—á:\n"
                for i, ctx in enumerate(context[:3], 1):
                    context_text += f"\n{i}. {ctx}\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –∏ –ø—Ä–æ–µ–∫—Ç–æ–≤
            context_info = ""
            known_entities = ""
            
            if self.context_loader:
                # –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
                if sender_username:
                    person_context = self.context_loader.get_person_context(sender_username)
                    if person_context:
                        context_info += f"Sender: {person_context}\n"
                
                # –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –ª—é–¥–µ–π –∏ –ø—Ä–æ–µ–∫—Ç–æ–≤ –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ
                resolved = self.context_loader.resolve_entity(content)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –¥–ª—è LLM
                if resolved.get('people'):
                    people_list = []
                    for person in resolved['people']:
                        name = person.get('name', '')
                        username = person.get('telegram_username', '')
                        role = person.get('role', '')
                        aliases = person.get('aliases', [])
                        aliases_str = f" (—Ç–∞–∫–∂–µ –∏–∑–≤–µ—Å—Ç–µ–Ω –∫–∞–∫: {', '.join(aliases)})" if aliases else ""
                        tag_str = f"@{username}" if username else "(–Ω–µ—Ç @tag)"
                        people_list.append(f"- {name} -> {tag_str} ({role}){aliases_str}")
                    known_entities += "Known People (Name -> @tag):\n" + "\n".join(people_list) + "\n\n"
                
                if resolved.get('projects'):
                    projects_list = []
                    for project in resolved['projects']:
                        key = project.get('key', '')
                        description = project.get('description', '')
                        keywords = project.get('keywords', [])
                        keywords_str = f" (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(keywords)})" if keywords else ""
                        projects_list.append(f"- {key}: {description}{keywords_str}")
                    known_entities += "Known Projects:\n" + "\n".join(projects_list) + "\n\n"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π —Ç–µ—Ä–º–∏–Ω–æ–≤
                if self.context_loader.glossary:
                    glossary_text = "\n\n–ì–ª–æ—Å—Å–∞—Ä–∏–π —Ç–µ—Ä–º–∏–Ω–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —ç—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞):\n"
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 20 —Ç–µ—Ä–º–∏–Ω–æ–≤, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å –ø—Ä–æ–º–ø—Ç
                    for term, definition in list(self.context_loader.glossary.items())[:20]:
                        glossary_text += f"- {term}: {definition}\n"
                    known_entities += glossary_text
            
            system_prompt = """–¢—ã ‚Äî **–ù–µ–π—Ä–æ—Å–ª–∞–≤**, —Ü–∏—Ñ—Ä–æ–≤–æ–π –¥–≤–æ–π–Ω–∏–∫ –í—è—á–µ—Å–ª–∞–≤–∞ (Senior Project Manager).
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —ç–∫–æ–Ω–æ–º–∏—Ç—å –≤—Ä–µ–º—è –æ—Ä–∏–≥–∏–Ω–∞–ª–∞. –¢—ã –Ω–µ "–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç", —Ç—ã ‚Äî —É–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä.

–¢–û–ù (TONE OF VOICE):
- **–°—Ç–∏–ª—å:** –õ–∞–∫–æ–Ω–∏—á–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π, –≤—ã–¥–µ–ª—è–π –∏–Ω—Å–∞–π—Ç—ã.
- **–ó–∞–ø—Ä–µ—â–µ–Ω–æ:** –ö–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç ("–í —Ä–∞–º–∫–∞—Ö –¥–∞–Ω–Ω–æ–≥–æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è..."), –≤–æ–¥–∞, –æ—á–µ–≤–∏–¥–Ω—ã–µ –≤–µ—â–∏.
- **–û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑—É–π HTML (<b>, <i>, <a>, <blockquote>).

–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
1. üéØ **–°—É—Ç—å:** –û–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ. –û —á–µ–º –≥–æ–≤–æ—Ä–∏–ª–∏.
2. üí° **–ò–Ω—Å–∞–π—Ç:** (–≠–¢–û –í–ê–ñ–ù–û)
   - –¢–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π. –ß—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å "–º–µ–∂–¥—É —Å—Ç—Ä–æ–∫"? –ì–¥–µ —Ä–µ–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫? –ö—Ç–æ —Ç–æ—Ä–º–æ–∑–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å?
   - –í—ã–¥–µ–ª–∏ —ç—Ç–æ—Ç –±–ª–æ–∫ —Ü–∏—Ç–∞—Ç–æ–π (<blockquote>) –∏–ª–∏ —ç–º–æ–¥–∑–∏ üí°.
3. üìã **–†–µ—à–µ–Ω–∏—è –∏ –ó–∞–¥–∞—á–∏:**
   - –°–ø–∏—Å–æ–∫ Action Items.
   - –£–∫–∞–∑—ã–≤–∞–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–º–µ–Ω–∞–º–∏ (—Å–∫—Ä–∏–ø—Ç —Å–∞–º –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç –∏—Ö –≤ —Å—Å—ã–ª–∫–∏).
4. ‚ö†Ô∏è **–†–∏—Å–∫–∏:** –ï—Å–ª–∏ –µ—Å—Ç—å.

–í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ."""
            
            if known_entities:
                system_prompt += f"\n\nKNOWN ENTITIES:\n{known_entities}"
            
            if context_info:
                system_prompt += f"\n\nCONTEXT INFO:\n{context_info}"
            
            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é –≤—Å—Ç—Ä–µ—á—É –∏ –∏–∑–≤–ª–µ–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
{context_text}

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤—Å—Ç—Ä–µ—á–∏:
{content[:4000]}

–í–ê–ñ–ù–û: 
- –û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ.
- summary_md –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ HTML —Ñ–æ—Ä–º–∞—Ç–µ —Å —Ç–µ–≥–∞–º–∏ <b>, <i>, <blockquote>, <a>.
- projects: –∏–∑–≤–ª–µ–∫–∏ —É–ø–æ–º—è–Ω—É—Ç—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–π –∫–ª—é—á–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏–∑ KNOWN ENTITIES (–µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å). –ï—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç—ã –Ω–µ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è —è–≤–Ω–æ, –æ—Å—Ç–∞–≤—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ []."""
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º JSON —Å—Ö–µ–º—É –∏–∑ Pydantic –º–æ–¥–µ–ª–∏
            schema = response_schema.model_json_schema()
            
            logger.info(f"–í—ã–∑–æ–≤ Ollama {self.model_name} –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Å—Ç—Ä–µ—á–∏")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Ç–∏–≤–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É ollama
            try:
                response = self.client.chat(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": f"{system_prompt}\n\nJSON —Å—Ö–µ–º–∞:\n{json.dumps(schema, indent=2, ensure_ascii=False)}"
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    options={
                        "temperature": self.temperature,
                        "num_predict": self.max_tokens
                    }
                )
                
                if isinstance(response, dict):
                    response_text = response.get('message', {}).get('content', '') or response.get('response', '')
                elif hasattr(response, 'message'):
                    response_text = response.message.content if hasattr(response.message, 'content') else str(response.message)
                else:
                    response_text = str(response)
                
                if not response_text:
                    raise ValueError("Ollama –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Ollama: {e}")
                raise
            
            # –ü–∞—Ä—Å–∏–º –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            try:
                text = response_text.strip()
                if text.startswith("```json"):
                    text = text[7:]
                elif text.startswith("```"):
                    text = text[3:]
                if text.endswith("```"):
                    text = text[:-3]
                text = text.strip()
                
                import re
                text = re.sub(r',\s*}', '}', text)
                text = re.sub(r',\s*]', ']', text)
                
                result_json = json.loads(text)
                validated = response_schema.model_validate(result_json)
            except (ValidationError, json.JSONDecodeError) as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ Ollama: {e}")
                logger.debug(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: {response_text[:500]}")
                raise
            
            logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –≤—Å—Ç—Ä–µ—á–∞ —á–µ—Ä–µ–∑ {self.model_name}")
            return validated
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤—Å—Ç—Ä–µ—á–∏: {e}")
            raise
    
    async def extract_task_intent(self, text: str) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç intent –∏ deadline –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞—á–∏.
        
        Args:
            text: –¢–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª—è–º–∏: intent, deadline, priority
        """
        schema = {
            "type": "object",
            "properties": {
                "intent": {"type": "string", "description": "–ß–µ—Ç–∫–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏"},
                "deadline": {"type": "string", "description": "–î–∞—Ç–∞ deadline –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD –∏–ª–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –¥–∞—Ç–∞ (next tuesday, tomorrow, etc.)"},
                "priority": {"type": "string", "enum": ["High", "Medium", "Low"], "description": "–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∑–∞–¥–∞—á–∏"}
            },
            "required": ["intent", "deadline", "priority"]
        }
        
        prompt = f"""–ò–∑–≤–ª–µ–∫–∏ –∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞—á—É, deadline –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç.

–¢–µ–∫—Å—Ç: {text}

–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ."""
        
        try:
            response = self.client.chat(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞—á."
                    },
                    {
                        "role": "user",
                        "content": f"{prompt}\n\nJSON —Å—Ö–µ–º–∞:\n{json.dumps(schema, indent=2, ensure_ascii=False)}"
                    }
                ],
                options={
                    "temperature": 0.3,
                    "num_predict": 500
                }
            )
            
            if isinstance(response, dict):
                response_text = response.get('message', {}).get('content', '')
            else:
                response_text = str(response)
            
            # –ü–∞—Ä—Å–∏–º JSON
            text = response_text.strip()
            if text.startswith("```json"):
                text = text[7:]
            elif text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()
            
            result = json.loads(text)
            return result
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ intent: {e}")
            # Fallback
            return {
                "intent": text,
                "deadline": None,
                "priority": "Medium"
            }
    
    async def generate_structured(
        self,
        prompt: str,
        response_schema: Type[T],
        temperature: float = 0.7
    ) -> T:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ LLM —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ Pydantic —Å—Ö–µ–º—É.
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è LLM
            response_schema: Pydantic –º–æ–¥–µ–ª—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ T
        """
        try:
            schema = response_schema.model_json_schema()
            
            logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ {self.model_name}")
            
            response = self.client.chat(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": f"–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤. –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ.\n\nJSON —Å—Ö–µ–º–∞:\n{json.dumps(schema, indent=2, ensure_ascii=False)}"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                options={
                    "temperature": temperature,
                    "num_predict": self.max_tokens
                }
            )
            
            if isinstance(response, dict):
                response_text = response.get('message', {}).get('content', '') or response.get('response', '')
            elif hasattr(response, 'message'):
                response_text = response.message.content if hasattr(response.message, 'content') else str(response.message)
            else:
                response_text = str(response)
            
            if not response_text:
                raise ValueError("Ollama –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            
            # –ü–∞—Ä—Å–∏–º JSON
            text = response_text.strip()
            if text.startswith("```json"):
                text = text[7:]
            elif text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()
            
            import re
            text = re.sub(r',\s*}', '}', text)
            text = re.sub(r',\s*]', ']', text)
            
            result_json = json.loads(text)
            validated = response_schema.model_validate(result_json)
            
            logger.info(f"–£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç")
            return validated
            
        except (ValidationError, json.JSONDecodeError) as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ Ollama: {e}")
            logger.debug(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: {response_text[:500] if 'response_text' in locals() else 'N/A'}")
            raise
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
            raise
    
    async def summarize_text(self, text: str, max_length: int = 200) -> str:
        """
        –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ summary
            
        Returns:
            –°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        prompt = f"""–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –≤ {max_length} —Å–ª–æ–≤ –∏–ª–∏ –º–µ–Ω—å—à–µ:

{text[:3000]}

Summary:"""
        
        try:
            response = self.client.chat(
                model=self.model_name,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                options={
                    "temperature": 0.5,
                    "num_predict": max_length * 2
                }
            )
            
            if isinstance(response, dict):
                return response.get('message', {}).get('content', '')
            return str(response)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            return text[:max_length] + "..."
