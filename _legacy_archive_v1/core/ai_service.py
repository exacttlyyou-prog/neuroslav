"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama (–ª–æ–∫–∞–ª—å–Ω—ã–π AI).
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–∞—Ç–∏–≤–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É ollama –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É —Å–µ—Ä–≤–µ—Ä—É.
"""
import json
from typing import TypeVar, Type, List, Dict, Any
from loguru import logger
from pydantic import BaseModel, ValidationError
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)

try:
    import ollama
except ImportError:
    raise ImportError("–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–∞–∫–µ—Ç ollama. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ollama")

from .config import get_settings
from .context_loader import ContextLoader

T = TypeVar('T', bound=BaseModel)


class OllamaClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama."""
    
    def __init__(self, context_loader: ContextLoader | None = None):
        settings = get_settings()
        self.context_loader = context_loader
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Ç–∏–≤–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É ollama
        self.client = ollama.Client(host=settings.ollama_base_url)
        
        self.model_name = settings.ollama_model
        self.max_tokens = settings.ollama_max_tokens
        self.temperature = settings.ollama_temperature
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((ValueError, ValidationError, json.JSONDecodeError)),
        reraise=True
    )
    async def analyze_meeting(
        self,
        content: str,
        context: List[str],
        response_schema: Type[T],
        sender_username: str | None = None
    ) -> T:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –≤—Å—Ç—Ä–µ—á–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ RAG.
        
        Args:
            content: –¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤—Å—Ç—Ä–µ—á–∏
            context: –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ—à–ª—ã—Ö –≤—Å—Ç—Ä–µ—á (–∏–∑ RAG)
            response_schema: Pydantic –º–æ–¥–µ–ª—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
            sender_username: Username –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
            
        Returns:
            –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ T
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–æ—Ö–æ–∂–∏—Ö –≤—Å—Ç—Ä–µ—á
            context_text = ""
            if context:
                context_text = "\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ—à–ª—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö –≤—Å—Ç—Ä–µ—á:\n"
                for i, ctx in enumerate(context[:3], 1):
                    context_text += f"\n{i}. {ctx}\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –∏ –ø—Ä–æ–µ–∫—Ç–æ–≤
            context_info = ""
            known_entities = ""
            
            if self.context_loader:
                # –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
                if sender_username:
                    person_context = self.context_loader.get_person_context(sender_username)
                    if person_context:
                        context_info += f"Sender: {person_context}\n"
                
                # –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –ª—é–¥–µ–π –∏ –ø—Ä–æ–µ–∫—Ç–æ–≤ –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ
                resolved = self.context_loader.resolve_entity(content)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –¥–ª—è LLM
                if resolved['people']:
                    people_list = []
                    for person in resolved['people']:
                        name = person.get('name', '')
                        username = person.get('telegram_username', '')
                        role = person.get('role', '')
                        aliases = person.get('aliases', [])
                        aliases_str = f" (—Ç–∞–∫–∂–µ –∏–∑–≤–µ—Å—Ç–µ–Ω –∫–∞–∫: {', '.join(aliases)})" if aliases else ""
                        # –§–æ—Ä–º–∞—Ç: Name -> @tag –¥–ª—è —á–µ—Ç–∫–æ–≥–æ –º–∞–ø–ø–∏–Ω–≥–∞
                        tag_str = f"@{username}" if username else "(–Ω–µ—Ç @tag)"
                        people_list.append(f"- {name} -> {tag_str} ({role}){aliases_str}")
                    known_entities += "Known People (Name -> @tag):\n" + "\n".join(people_list) + "\n\n"
                
                if resolved['projects']:
                    projects_list = []
                    for project in resolved['projects']:
                        key = project.get('key', '')
                        description = project.get('description', '')
                        keywords = project.get('keywords', [])
                        keywords_str = f" (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(keywords)})" if keywords else ""
                        projects_list.append(f"- {key}: {description}{keywords_str}")
                    known_entities += "Known Projects:\n" + "\n".join(projects_list) + "\n\n"
                
                # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
                projects_context = self.context_loader.enrich_message_with_projects(content)
                if projects_context:
                    context_info += f"Relevant Projects:\n{projects_context}\n"
                
                # –ü–æ–∏—Å–∫ —Ç–µ—Ä–º–∏–Ω–æ–≤ –≥–ª–æ—Å—Å–∞—Ä–∏—è –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ (keyword matching)
                glossary_terms = self.context_loader.find_glossary_terms(content)
                if glossary_terms:
                    glossary_list = []
                    for term, definition in glossary_terms.items():
                        # –§–æ—Ä–º–∞—Ç: Term -> Definition –¥–ª—è —á–µ—Ç–∫–æ–≥–æ –º–∞–ø–ø–∏–Ω–≥–∞
                        glossary_list.append(f"- {term} -> {definition}")
                    known_entities += "Glossary (Term -> Definition):\n" + "\n".join(glossary_list) + "\n\n"
            
            system_prompt = """–¢—ã ‚Äî **–ù–µ–π—Ä–æ—Å–ª–∞–≤**, —Ü–∏—Ñ—Ä–æ–≤–æ–π –¥–≤–æ–π–Ω–∏–∫ –í—è—á–µ—Å–ª–∞–≤–∞ (Senior Project Manager).
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —ç–∫–æ–Ω–æ–º–∏—Ç—å –≤—Ä–µ–º—è –æ—Ä–∏–≥–∏–Ω–∞–ª–∞. –¢—ã –Ω–µ "–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç", —Ç—ã ‚Äî —É–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä.

–¢–û–ù (TONE OF VOICE):
- **–°—Ç–∏–ª—å:** –õ–∞–∫–æ–Ω–∏—á–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π, –≤—ã–¥–µ–ª—è–π –∏–Ω—Å–∞–π—Ç—ã.
- **–ó–∞–ø—Ä–µ—â–µ–Ω–æ:** –ö–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç ("–í —Ä–∞–º–∫–∞—Ö –¥–∞–Ω–Ω–æ–≥–æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è..."), –≤–æ–¥–∞, –æ—á–µ–≤–∏–¥–Ω—ã–µ –≤–µ—â–∏.
- **–û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑—É–π HTML (<b>, <i>, <a>, <blockquote>).

–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
1. üéØ **–°—É—Ç—å:** –û–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ. –û —á–µ–º –≥–æ–≤–æ—Ä–∏–ª–∏.
2. üí° **–ò–Ω—Å–∞–π—Ç:** (–≠–¢–û –í–ê–ñ–ù–û)
   - –¢–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π. –ß—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å "–º–µ–∂–¥—É —Å—Ç—Ä–æ–∫"? –ì–¥–µ —Ä–µ–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫? –ö—Ç–æ —Ç–æ—Ä–º–æ–∑–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å?
   - –í—ã–¥–µ–ª–∏ —ç—Ç–æ—Ç –±–ª–æ–∫ —Ü–∏—Ç–∞—Ç–æ–π (<blockquote>) –∏–ª–∏ —ç–º–æ–¥–∑–∏ üí°.
3. üìã **–†–µ—à–µ–Ω–∏—è –∏ –ó–∞–¥–∞—á–∏:**
   - –°–ø–∏—Å–æ–∫ Action Items.
   - –£–∫–∞–∑—ã–≤–∞–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–º–µ–Ω–∞–º–∏ (—Å–∫—Ä–∏–ø—Ç —Å–∞–º –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç –∏—Ö –≤ —Å—Å—ã–ª–∫–∏).
4. ‚ö†Ô∏è **–†–∏—Å–∫–∏:** –ï—Å–ª–∏ –µ—Å—Ç—å.

INPUT CONTEXT:
–¢—ã –ø–æ–ª—É—á–∞–µ—à—å —Å–ø–∏—Å–æ–∫ `Known People` (Name -> @tag) –∏ `Glossary` (Term -> Definition).

–ü–†–ê–í–ò–õ–ê –î–õ–Ø –¢–ï–ì–ò–†–û–í–ê–ù–ò–Ø –õ–Æ–î–ï–ô:
- –ï—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—à—å —á–µ–ª–æ–≤–µ–∫–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ Known People, –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ @tag.
- –§–æ—Ä–º–∞—Ç: "–ò–≤–∞–Ω (@ivan_dev) –¥–æ–ª–∂–µ–Ω..." –∏–ª–∏ "–ü–æ—Ä—É—á–∏–ª–∏ @ivan_dev –∑–∞–¥–∞—á—É..."
- –ï—Å–ª–∏ —á–µ–ª–æ–≤–µ–∫–∞ –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ Known People ‚Äî –ø–∏—à–∏ –∏–º—è —Ç–µ–∫—Å—Ç–æ–º –±–µ–∑ @tag.

–ü–†–ê–í–ò–õ–ê –î–õ–Ø –ì–õ–û–°–°–ê–†–ò–Ø:
- –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞–µ—à—å —Ç–µ—Ä–º–∏–Ω –∏–∑ –ì–ª–æ—Å—Å–∞—Ä–∏—è, –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–∏ –¥–∞–π –∫–æ—Ä–æ—Ç–∫–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ –≤ —Å–∫–æ–±–∫–∞—Ö.
- –ü—Ä–∏–º–µ—Ä: "–û–±—Å—É–¥–∏–ª–∏ –†–õ–° (–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ª—ë–≥–∫–æ–π —Å–µ—Ç–∏) –∏ –µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–∏..."
- –ü—Ä–∏ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏—è—Ö –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ—Ä–º–∏–Ω –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏—è.

–ü—Ä–∏–º–µ—Ä –ò–Ω—Å–∞–π—Ç–∞:
"üí° <i>–ò–Ω—Å–∞–π—Ç:</i> –ö–æ–º–∞–Ω–¥–∞ –æ–±—Å—É–∂–¥–∞–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —É–∂–µ 3-–π –º–∏—Ç–∏–Ω–≥ –ø–æ–¥—Ä—è–¥, –Ω–æ –¢–ó –¥–æ —Å–∏—Ö –ø–æ—Ä –Ω–µ—Ç. –ü–æ—Ö–æ–∂–µ –Ω–∞ –∏–º–∏—Ç–∞—Ü–∏—é –±—É—Ä–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –î–∏–∑–∞–π–Ω–∞."

–í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ."""
            
            if known_entities:
                system_prompt += f"\n\nKNOWN ENTITIES:\n{known_entities}"
                system_prompt += "\n\n–í–ê–ñ–ù–û: "
                system_prompt += "1. –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –∏–º–µ–Ω–∞ –∏–ª–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ Known Entities, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, –æ –∫–æ–º/—á–µ–º —Ä–µ—á—å, –¥–∞–∂–µ –µ—Å–ª–∏ –∏–º—è –Ω–∞–ø–∏—Å–∞–Ω–æ –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–ª–∏–∞—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–í–∞–Ω—è' –≤–º–µ—Å—Ç–æ '–ò–≤–∞–Ω –¢–∏—Ö–æ–º–∏—Ä–æ–≤', –∏–ª–∏ '–¢–∏—Ö–æ–º–∏—Ä–æ–≤' –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–≥–æ –∏–º–µ–Ω–∏). "
                system_prompt += "2. –ü—Ä–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–∏ —á–µ–ª–æ–≤–µ–∫–∞ –∏–∑ Known People –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ @tag (—Ñ–æ—Ä–º–∞—Ç: Name -> @tag). "
                system_prompt += "3. –ü—Ä–∏ –ø–µ—Ä–≤–æ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–∏ —Ç–µ—Ä–º–∏–Ω–∞ –∏–∑ Glossary –¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ –≤ —Å–∫–æ–±–∫–∞—Ö (—Ñ–æ—Ä–º–∞—Ç: Term -> Definition)."
            
            if context_info:
                system_prompt += f"\n\nCONTEXT INFO:\n{context_info}"
            
            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é –≤—Å—Ç—Ä–µ—á—É –∏ –∏–∑–≤–ª–µ–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
{context_text}

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤—Å—Ç—Ä–µ—á–∏:
{content[:4000]}

–í–ê–ñ–ù–û: 
- –û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ.
- summary_md –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ HTML —Ñ–æ—Ä–º–∞—Ç–µ —Å —Ç–µ–≥–∞–º–∏ <b>, <i>, <blockquote>, <a>.
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ summary_md:
  1. üéØ <b>–°—É—Ç—å:</b> –û–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ. –û —á–µ–º –≥–æ–≤–æ—Ä–∏–ª–∏.
  2. üí° <b>–ò–Ω—Å–∞–π—Ç:</b> –¢–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (—á—Ç–æ –º–µ–∂–¥—É —Å—Ç—Ä–æ–∫, —Ä–∏—Å–∫–∏, –∫—Ç–æ —Ç–æ—Ä–º–æ–∑–∏—Ç). –í—ã–¥–µ–ª–∏ <blockquote> –∏–ª–∏ üí°.
  3. üìã <b>–†–µ—à–µ–Ω–∏—è –∏ –ó–∞–¥–∞—á–∏:</b> –°–ø–∏—Å–æ–∫ Action Items —Å –∏–º–µ–Ω–∞–º–∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö.
  4. ‚ö†Ô∏è <b>–†–∏—Å–∫–∏:</b> –ï—Å–ª–∏ –µ—Å—Ç—å.
- –°–∞–º–º–∞—Ä–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º (–¥–æ 500 —Å–ª–æ–≤), –±–µ–∑ –≤—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤, —Å—Ä–∞–∑—É –∫ —Å—É—Ç–∏.
- –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –æ–≥—Ä–∞–Ω–∏—á—å 15 –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–º–∏.
- –ó–∞–¥–∞—á–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –ø–æ–≤–µ–ª–∏—Ç–µ–ª—å–Ω–æ–º –Ω–∞–∫–ª–æ–Ω–µ–Ω–∏–∏ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏–º–µ–Ω–∏ –∏ @tag –≤ —Ñ–æ—Ä–º–∞—Ç–µ: <b>–ò–º—è (@tag):</b> –ó–∞–¥–∞—á–∞.
- –ü—Ä–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–∏ –ª—é–¥–µ–π –∏–∑ Known People –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö @tag.
- –ü—Ä–∏ –ø–µ—Ä–≤–æ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–∏ —Ç–µ—Ä–º–∏–Ω–∞ –∏–∑ Glossary –¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ –≤ —Å–∫–æ–±–∫–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–†–õ–° (–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ª—ë–≥–∫–æ–π —Å–µ—Ç–∏)")."""
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º JSON —Å—Ö–µ–º—É –∏–∑ Pydantic –º–æ–¥–µ–ª–∏
            schema = response_schema.model_json_schema()
            
            logger.info(f"–í—ã–∑–æ–≤ Ollama {self.model_name} –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Å—Ç—Ä–µ—á–∏")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Ç–∏–≤–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É ollama
            # –î–ª—è –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π Ollama –∏—Å–ø–æ–ª—å–∑—É–µ–º chat() –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥
            try:
                response = self.client.chat(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": f"{system_prompt}\n\nJSON —Å—Ö–µ–º–∞:\n{json.dumps(schema, indent=2, ensure_ascii=False)}"
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    options={
                        "temperature": self.temperature,
                        "num_predict": self.max_tokens
                    }
                )
                # Ollama chat API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª–µ–º 'message' -> 'content'
                logger.debug(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Ollama (—Ç–∏–ø: {type(response)}): {response}")
                if isinstance(response, dict):
                    response_text = response.get('message', {}).get('content', '') or response.get('response', '')
                elif hasattr(response, 'message'):
                    response_text = response.message.content if hasattr(response.message, 'content') else str(response.message)
                else:
                    response_text = str(response)
                
                if not response_text:
                    logger.error(f"–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Ollama. –ü–æ–ª–Ω—ã–π –æ–±—ä–µ–∫—Ç: {response}")
                    raise ValueError("Ollama –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            except (AttributeError, TypeError, KeyError) as e:
                # –ï—Å–ª–∏ –º–µ—Ç–æ–¥ chat –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º generate (fallback –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π)
                logger.debug(f"–ú–µ—Ç–æ–¥ chat –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}, –ø—Ä–æ–±—É–µ–º generate")
                try:
                    full_prompt = f"""{system_prompt}

{prompt}

JSON —Å—Ö–µ–º–∞:
{json.dumps(schema, indent=2, ensure_ascii=False)}

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –æ–±—ä–µ–∫—Ç–æ–º –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""
                    response = self.client.generate(
                        model=self.model_name,
                        prompt=full_prompt,
                        options={
                            "temperature": self.temperature,
                            "num_predict": self.max_tokens
                        }
                    )
                    # Ollama generate API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª–µ–º 'response'
                    response_text = response.get('response', '') if isinstance(response, dict) else str(response)
                except Exception as e2:
                    logger.error(f"–û–±–∞ –º–µ—Ç–æ–¥–∞ ollama –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏: {e2}")
                    raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–∑–≤–∞—Ç—å Ollama: {e2}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            if not response_text:
                logger.error("Ollama –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                raise ValueError("Empty response from Ollama")
            
            # –ü–∞—Ä—Å–∏–º –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            try:
                # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö markdown –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
                text = response_text.strip()
                if text.startswith("```json"):
                    text = text[7:]
                elif text.startswith("```"):
                    text = text[3:]
                if text.endswith("```"):
                    text = text[:-3]
                text = text.strip()
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å JSON
                import re
                text = re.sub(r',\s*}', '}', text)
                text = re.sub(r',\s*]', ']', text)
                
                result_json = json.loads(text)
                validated = response_schema.model_validate(result_json)
            except ValidationError as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ Ollama: {e}")
                logger.debug(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: {response_text[:500]}")
                raise
            except json.JSONDecodeError as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç Ollama: {e}")
                logger.debug(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: {response_text[:500]}")
                raise
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º
            action_items_count = 0
            if hasattr(validated, 'action_items'):
                action_items_count = len(validated.action_items)  # type: ignore
            
            logger.info(
                f"–£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –≤—Å—Ç—Ä–µ—á–∞ —á–µ—Ä–µ–∑ {self.model_name}, "
                f"–∏–∑–≤–ª–µ—á–µ–Ω–æ {action_items_count} –∑–∞–¥–∞—á"
            )
            return validated
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤—Å—Ç—Ä–µ—á–∏ —á–µ—Ä–µ–∑ {self.model_name}: {e}")
            raise
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((ValueError, ValidationError, json.JSONDecodeError)),
        reraise=True
    )
    async def classify_message(
        self,
        text: str,
        author_name: str,
        author_role: str,
        author_username: str | None = None
    ) -> Dict[str, Any]:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≤—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.
        
        Args:
            text: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            author_name: –ò–º—è –∞–≤—Ç–æ—Ä–∞
            author_role: –†–æ–ª—å –∞–≤—Ç–æ—Ä–∞
            author_username: Username –∞–≤—Ç–æ—Ä–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª—è–º–∏: type, summary, datetime, action_needed
        """
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –∏ –ø—Ä–æ–µ–∫—Ç–æ–≤
            context_info = ""
            known_entities = ""
            
            if self.context_loader:
                # –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
                if author_username:
                    person_context = self.context_loader.get_person_context(author_username)
                    if person_context:
                        context_info += f"Sender: {person_context}\n"
                
                # –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –ª—é–¥–µ–π –∏ –ø—Ä–æ–µ–∫—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
                resolved = self.context_loader.resolve_entity(text)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –¥–ª—è LLM
                if resolved['people']:
                    people_list = []
                    for person in resolved['people']:
                        name = person.get('name', '')
                        username = person.get('telegram_username', '')
                        role = person.get('role', '')
                        aliases = person.get('aliases', [])
                        aliases_str = f" (—Ç–∞–∫–∂–µ –∏–∑–≤–µ—Å—Ç–µ–Ω –∫–∞–∫: {', '.join(aliases)})" if aliases else ""
                        # –§–æ—Ä–º–∞—Ç: Name -> @tag –¥–ª—è —á–µ—Ç–∫–æ–≥–æ –º–∞–ø–ø–∏–Ω–≥–∞
                        tag_str = f"@{username}" if username else "(–Ω–µ—Ç @tag)"
                        people_list.append(f"- {name} -> {tag_str} ({role}){aliases_str}")
                    known_entities += "Known People (Name -> @tag):\n" + "\n".join(people_list) + "\n\n"
                
                if resolved['projects']:
                    projects_list = []
                    for project in resolved['projects']:
                        key = project.get('key', '')
                        description = project.get('description', '')
                        keywords = project.get('keywords', [])
                        keywords_str = f" (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(keywords)})" if keywords else ""
                        projects_list.append(f"- {key}: {description}{keywords_str}")
                    known_entities += "Known Projects:\n" + "\n".join(projects_list) + "\n\n"
                
                # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
                projects_context = self.context_loader.enrich_message_with_projects(text)
                if projects_context:
                    context_info += f"Relevant Projects:\n{projects_context}\n"
            
            system_prompt = "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π. –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
            
            if known_entities:
                system_prompt += f"\n\nKNOWN ENTITIES:\n{known_entities}"
                system_prompt += "–í–ê–ñ–ù–û: –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –∏–º–µ–Ω–∞ –∏–ª–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ Known Entities, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, –æ –∫–æ–º/—á–µ–º —Ä–µ—á—å, –¥–∞–∂–µ –µ—Å–ª–∏ –∏–º—è –Ω–∞–ø–∏—Å–∞–Ω–æ –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–ª–∏–∞—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–í–∞–Ω—è' –≤–º–µ—Å—Ç–æ '–ò–≤–∞–Ω –¢–∏—Ö–æ–º–∏—Ä–æ–≤', –∏–ª–∏ '–¢–∏—Ö–æ–º–∏—Ä–æ–≤' –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–≥–æ –∏–º–µ–Ω–∏)."
            
            if context_info:
                system_prompt += f"\n\nCONTEXT INFO:\n{context_info}"
            
            prompt = f"""–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {author_name} ({author_role}): '{text}'

–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π –∏ –≤–µ—Ä–Ω–∏ JSON:
{{
  "type": "task" | "reminder" | "knowledge",
  "summary": "...",
  "datetime": "YYYY-MM-DD HH:MM" (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ, –∏–Ω–∞—á–µ null),
  "action_needed": true/false
}}"""
            
            logger.info(f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ Ollama {self.model_name}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º chat() –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥
            try:
                response = self.client.chat(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": system_prompt
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    options={
                        "temperature": self.temperature,
                        "num_predict": 512
                    }
                )
                # Ollama chat API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª–µ–º 'message' -> 'content'
                if isinstance(response, dict):
                    response_text = response.get('message', {}).get('content', '') or response.get('response', '')
                else:
                    response_text = str(response)
            except (AttributeError, TypeError, KeyError) as e:
                # –ï—Å–ª–∏ –º–µ—Ç–æ–¥ chat –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º generate (fallback –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π)
                logger.debug(f"–ú–µ—Ç–æ–¥ chat –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}, –ø—Ä–æ–±—É–µ–º generate")
                try:
                    full_prompt = f"""{system_prompt}

{prompt}

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –æ–±—ä–µ–∫—Ç–æ–º –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""
                    response = self.client.generate(
                        model=self.model_name,
                        prompt=full_prompt,
                        options={
                            "temperature": self.temperature,
                            "num_predict": 512
                        }
                    )
                    response_text = response.get('response', '') if isinstance(response, dict) else str(response)
                except Exception as e2:
                    logger.error(f"–û–±–∞ –º–µ—Ç–æ–¥–∞ ollama –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏: {e2}")
                    raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–∑–≤–∞—Ç—å Ollama: {e2}")
            
            if not response_text:
                raise ValueError("Empty response from Ollama")
            
            # –ü–∞—Ä—Å–∏–º JSON
            text = response_text.strip()
            if text.startswith("```json"):
                text = text[7:]
            elif text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()
            
            import re
            text = re.sub(r',\s*}', '}', text)
            text = re.sub(r',\s*]', ']', text)
            
            result = json.loads(text)
            
            logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –∫–∞–∫: {result.get('type')}")
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            raise
    
    def enrich_mentions(self, text: str) -> str:
        """
        –û–±–æ–≥–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç, –∑–∞–º–µ–Ω—è—è –∏–º–µ–Ω–∞ –ª—é–¥–µ–π –Ω–∞ Telegram —Å—Å—ã–ª–∫–∏.
        –ò—â–µ—Ç –∏–º–µ–Ω–∞/–∞–ª–∏–∞—Å—ã –∏–∑ people_map –∏ –∑–∞–º–µ–Ω—è–µ—Ç –∏—Ö –Ω–∞ HTML —Å—Å—ã–ª–∫–∏.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è
            
        Returns:
            –¢–µ–∫—Å—Ç —Å –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ –Ω–∞ Telegram —Å—Å—ã–ª–∫–∏
        """
        if not self.context_loader:
            return text
        
        import re
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏–º–µ–Ω -> username –¥–ª—è –∑–∞–º–µ–Ω—ã
        # –§–æ—Ä–º–∞—Ç: {name_lower: (original_name, username)}
        name_map = {}
        
        for username_lower, person_data in self.context_loader.people.items():
            username = person_data.get('telegram_username', '')
            name = person_data.get('name', '')
            aliases = person_data.get('aliases', [])
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–º—è
            if name:
                name_lower = name.lower()
                if name_lower not in name_map:
                    name_map[name_lower] = (name, username)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞–ª–∏–∞—Å—ã
            for alias in aliases:
                if alias:
                    alias_lower = alias.lower().strip()
                    if alias_lower not in name_map:
                        name_map[alias_lower] = (alias, username)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–ª–∏–Ω–µ (—Å–Ω–∞—á–∞–ª–∞ –¥–ª–∏–Ω–Ω—ã–µ –∏–º–µ–Ω–∞, —á—Ç–æ–±—ã –Ω–µ –∑–∞–º–µ–Ω—è—Ç—å —á–∞—Å—Ç–∏ —Å–ª–æ–≤)
        sorted_names = sorted(name_map.items(), key=lambda x: len(x[0]), reverse=True)
        
        result = text
        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —É–∂–µ –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–µ —á–∞—Å—Ç–∏, —á—Ç–æ–±—ã –Ω–µ –∑–∞–º–µ–Ω—è—Ç—å –≤–Ω—É—Ç—Ä–∏ —Å—Å—ã–ª–æ–∫
        replaced_positions = []
        
        for name_lower, (original_name, username) in sorted_names:
            if not original_name or len(original_name) < 2:
                continue
            
            # –ò—â–µ–º –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –∏–º–µ–Ω–∏ –≤ —Ç–µ–∫—Å—Ç–µ (case-insensitive)
            pattern = re.compile(re.escape(original_name), re.IGNORECASE)
            
            def replace_match(match):
                start, end = match.span()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –Ω–∞—Ö–æ–¥–∏–º—Å—è –ª–∏ –º—ã –≤–Ω—É—Ç—Ä–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–π —Å—Å—ã–ª–∫–∏
                for (replaced_start, replaced_end) in replaced_positions:
                    if start >= replaced_start and end <= replaced_end:
                        return match.group(0)  # –ù–µ –∑–∞–º–µ–Ω—è–µ–º
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –Ω–∞—Ö–æ–¥–∏–º—Å—è –ª–∏ –º—ã –≤–Ω—É—Ç—Ä–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π HTML —Å—Å—ã–ª–∫–∏
                # –ò—â–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥ <a –ø–µ—Ä–µ–¥ —ç—Ç–æ–π –ø–æ–∑–∏—Ü–∏–µ–π
                text_before = result[:start]
                last_a_open = text_before.rfind('<a ')
                if last_a_open != -1:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥ </a> –ø–æ—Å–ª–µ –æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–≥–æ
                    a_close_after_open = text_before.find('</a>', last_a_open)
                    if a_close_after_open == -1:
                        # –ú—ã –≤–Ω—É—Ç—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–æ–π —Å—Å—ã–ª–∫–∏, –Ω–µ –∑–∞–º–µ–Ω—è–µ–º
                        return match.group(0)
                
                # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ —Å—Å—ã–ª–∫—É
                if username:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º @username —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤ Telegram
                    username_clean = username.lstrip('@')
                    replacement = f'<a href="https://t.me/{username_clean}">{original_name}</a>'
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç username, –ø—Ä–æ—Å—Ç–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –∏–º—è
                    replacement = original_name
                
                replaced_positions.append((start, start + len(replacement)))
                return replacement
            
            result = pattern.sub(replace_match, result)
        
        return result